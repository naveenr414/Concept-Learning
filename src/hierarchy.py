from scipy.cluster.hierarchy import dendrogram, linkage, ward
from sklearn.cluster import AgglomerativeClustering
from scipy.spatial.distance import pdist, cdist
from scipy.sparse.csgraph import minimum_spanning_tree
import numpy as np
from zss import simple_distance, Node
import sklearn
from math import ceil

class Split:
    """Class that captures a split in a dendogram. 
        It essentially functions similar to a binary tree
        The left_split and right_split attributes are the child splits, 
        While the value is stored for leaf splits, where the height = 0
        
        Attributes:
            leaf: Boolean that says if split is a leaf Split
            left_split: Object from Split class that represents left child
            right_split: Object from Split class that represents right child
            split_height: Y coordinate at which the split occurs; 0 for leaves
            value: For leaf nodes, what value the nodes take up, as a list
                For non-leaf nodes, it's a sorted list of the values taken by their children
    """
      
    
    def __init__(self,split_height,left_split,right_split,value=None):
        if split_height == 0 and left_split == None and right_split == None:
            self.leaf = True
            self.value = [value]

        else:
            self.leaf = False
            self.value = sorted(left_split.value + right_split.value)
        
        self.left_split = left_split
        self.right_split = right_split
        self.split_height = split_height 

    def print_split(self,split,spaces = ""):
        """Recursive function to print out a split horizontally
        
        Arguments: 
            split: Object from the split class to print
            spaces: Optional Argument that says how far to tab in 
                each value; this increases as you 
                go further down the dendrogram

        Returns: 
            String value of the split
        """
        
        if split.leaf:
            ret = spaces+" ---- "+split.value[0]+"\n"
        else:
            ret = self.print_split(split.left_split,spaces+" "*5)
            ret += spaces + " ----|"
            ret += "\n"
            ret += self.print_split(split.right_split,spaces+" "*5)
            ret += "\n"
            
        return ret
    
    def to_node(self):
        """Return a Node object from the zss library, using concept names as the values
        
        Arguments: Nothing
        
        Returns: Node object from the zss library"""
        
        if self.leaf:
            return Node(self.value[0])
        n = Node(" ".join(self.value))
        
        if self.left_split.value[0] < self.right_split.value[0]:
            n.addkid(self.left_split.to_node())
            n.addkid(self.right_split.to_node())
        else:
            n.addkid(self.right_split.to_node())
            n.addkid(self.left_split.to_node())

        
        return n
    
    def __str__(self):
        """Creates a string version of the split, as a dendrogram
        
        Arguments: Nothing
        
        Returns: String version of the split
        """
        
        return self.print_split(self)

        
class Hierarchy:
    """Stores a root split, and uses that to convert Hierarchies into numpy arrays and vice-versa
        This class is useful to investigate and print hierarchies, and also to compute distances
        
    Attributes:
        root_split: Split that contains information on all other splits
    """
    
    def __init__(self,root_split=None):
        self.root_split = root_split
        
    def from_array(self,arr,baseline_concepts):
        """From a numpy array, arr, generate the hierarchy and store it in root_split
        We do this by first generating baseline splits for the concepts, then 
            creating splits in order of height
        
        Arguments:
            arr: Numpy array generated by a hierarchy producing method from SkLearn
            baseline_concepts: Names for the leaf nodes
            
        Returns: Nothing
        
        Side Effects: Sets the data from arr to be in root_split
        """
        
        arr[:,2] += .01
        
        split_list = []
                
        for concept in baseline_concepts:
            s = Split(0,None,None,concept)
            split_list.append(s)
            
        for row in arr:
            split_left = int(row[0])
            split_right = int(row[1])
            distance = row[2]
            
            new_split = Split(distance,split_list[split_left],
                              split_list[split_right])
            split_list.append(new_split)
            
        self.root_split = split_list[-1]
            
        return None
        
    def get_all_splits(self):
        """Perform DFS on the splits, and return an array of all the nodes/splits
        
        Arguments: Nothing
        
        Returns: 
            Array of splits in DFS order
        """
        
        to_visit = [self.root_split]
        ret_array = []
        
        while len(to_visit) > 0:
            current_node = to_visit.pop()
            if current_node == None:
                continue
            
            ret_array.append(current_node)
            to_visit.append(current_node.left_split)
            to_visit.append(current_node.right_split)
            
        return ret_array
        
    def to_array(self, baseline_concepts):
        """Return a numpy array from the data stored in root_split 
        We do this by first generating the leaf nodes from the baseline concepts
        Then getting the non-leaf nodes, sorted by height
        We go through each split and get the index of the left and right child, 
            then add it to a numpy array
        This array should have n-1 rows, which correspond to the n-1 splits (for n concepts
        
        Arguments: Nothing
        
        Returns: 
            Numpy array, with information on how to construct a histogram
        """
        
        baseline_splits = [[[i],0] for i in baseline_concepts]
        concept_to_num = {}
        for i,value in enumerate(baseline_concepts):
            concept_to_num[value] = i
        
        hierarchy_splits = self.get_all_splits()
        hierarchy_splits = [i for i in hierarchy_splits if not i.leaf]
                
        sorted_splits = [[i.value,i.split_height,i.left_split.value,i.right_split.value] for i in hierarchy_splits]
        sorted_splits = sorted(sorted_splits, key=lambda k: k[1])
        
        ret_matrix = []
        for value,split_height,left_split,right_split in sorted_splits:
            concept_to_num[" ".join(value)] = len(concept_to_num)
            
            left_split_num = float(concept_to_num[" ".join(left_split)])
            right_split_num = float(concept_to_num[" ".join(right_split)])
            split_len = len(value)
            ret_matrix.append([left_split_num,right_split_num,split_height,split_len])
            
        return ret_matrix        
        
    def distance(self,other_hierarchy):
        """Distance from one hierarchy to another. 
            Calculated by converting hierarchy to a tree, then computing tree-edit distance
            
        Arguments:
            other_hierarchy: Another object from the class Hierarchy

        Returns: 
            float that represents distance between two hierarchies
        
        """
        
        our_node = self.root_split.to_node()
        their_node = other_hierarchy.root_split.to_node()
        
        return simple_distance(our_node,their_node)
        
    def __str__(self):
        """Convert a hierarchy into a printable string
        
        Arguments: Nothing
        
        Returns:
            String which shows a human-understandable version of the dendrogram
            If dendogram is large, then we encourage saving it to a file         
        """
        
        return str(self.root_split).strip("\n")
    
def create_ward_hierarchy(data,metric='euclidean'):
    """Use the sklearn ward function to construct a hierarchal cluster
    
    Arguments:
        data: Numpy array of data/array of numpy vectors

    Returns: 
        numpy array with information on how to construct a dendogram
    """
    
    return ward(data)

def create_linkage_hierarchy(data,method='single',metric='euclidean'):
    """Use the sklearn linkage function to construct a hierarchal cluster
    
    Arguments:
        data: Numpy array of data/array of numpy vectors
        method: What type of linkage, such as 'single', 'complete', or 'average'
        mertic: What metric to use, such as 'euclidean', 'chebyshev', 'cosine', etc.

    Returns:
        numpy array with information on how to construct a dendogram
        This can be fed into the dendrogram method to plot it
    """
    
    return linkage(data,method=method,metric=metric)

def create_hierarchy_thresholding(data,metric='euclidean'):
    """Use a thresholding algorithm with a minimum spanning tree to construct a hierarcha cluster
    
    Arguments:
        data: Numpy array of data/array of numpy vectors
        metric: What metric to use, such as 'euclidean', 'chebyshev', 'cosine', etc. 
        
    Returns:
        numpy array with information on how to construct a dendrogram
        This can be fed into the dendrogram method to plot it

    """
    
    distance_matrix = cdist(data,data,metric=metric)
    tree = minimum_spanning_tree(distance_matrix)
    tree = tree.toarray().astype(int)
    
    node_combinations = []
    for i in range(len(tree)):
        for j in range(len(tree[i])):
            if tree[i][j]>0:
                node_combinations.append((i,j,tree[i][j]))

    node_combinations = sorted(node_combinations,key=lambda k: k[2])
    
    # Create a matrix in the dendrogram format (https://stackoverflow.com/questions/9838861/scipy-linkage-format)
    return_matrix = np.zeros((len(data)-1,4))
    new_clusters = [[i] for i in range(len(data))]
    
    current_num = 0
    
    for u,v,dist in node_combinations:
        # Combine nodes u, v
        u_cluster = max([i for i in range(len(new_clusters)) if u in new_clusters[i]])
        v_cluster = max([i for i in range(len(new_clusters)) if v in new_clusters[i]])
            
        cluster_size = len(new_clusters[u_cluster]) + len(new_clusters[v_cluster])

        new_cluster = new_clusters[u_cluster] + new_clusters[v_cluster]
        new_cluster = list(set(new_cluster))
        new_clusters.append(new_cluster)
        
        return_matrix[current_num] = np.array([u_cluster,v_cluster,dist,cluster_size])
        current_num += 1
        
    return return_matrix

def flat_distance_to_square(distance_matrix):
    """Convert a flat distance list, which contains the distances from object 1 to objects 1...n, then object 2 to 2...n, etc.
        to a distance matrix of size nxn
        
    Arguments: Numpy array distance_matrix which is a numpy list of size n(n-1)/2
    
    Returns: Numpy array of size nxn
    """
    
    n = ceil((2*len(distance_matrix))**.5)
    new_distances = np.zeros((n,n))
    
    current_num = 0
    
    for i in range(n):
        for j in range(i+1,n):            
            new_distances[i][j] = distance_matrix[current_num]
            new_distances[j][i] = distance_matrix[current_num]
           
            current_num += 1
            
    return new_distances


def get_concept_distances(embedding_method,dataset,suffix,attributes,random_seed):
    """Compute a numpy distance matrix between every pair of concepts
    
    Arguments:
        embedding_method: A simplified embedding creation method, such as load_cem_vectors_simple; 
            Simply loads embeddings, does not train them from scratch 
        dataset: Object from the dataset class
        suffix: String, which specific instance of the dataset we're using 
        attributes: List of attributes we want to create embeddings for
        random_seed: Number representing the random seed for the embeddings
        
    Returns: Numpy distance matrix

    """
    
    distance_matrix = []
    
    embeddings_by_attribute = {}
    
    for attribute in attributes:
        embeddings = embedding_method(attribute,dataset,suffix,seed=random_seed)
        embeddings_by_attribute[attribute] = embeddings
        
    for i in range(len(attributes)):
        for j in range(i+1,len(attributes)):
            embeddings_i = embeddings_by_attribute[attributes[i]]
            embeddings_j = embeddings_by_attribute[attributes[j]]
            
            all_pairwise_distances = sklearn.metrics.pairwise_distances(embeddings_i,embeddings_j)
            distance = np.mean(all_pairwise_distances)
            distance_matrix.append(distance)
    
    distance_matrix = np.array(distance_matrix)
    
    return distance_matrix

def create_hierarchy(hierarchy_method, embedding_method,dataset,suffix,attributes,random_seed):
    """Create a hierarchy from a set of embeddings and a dataset
    Do this by first creating a distance matrix (pdist-style), then feeding it into hierarchy_method
    
    Arguments:
        hierarchy_method: Function such as create_ward_hierarchy that creates a dendrogram
        embedding_method: A simplified embedding creation method, such as load_cem_vectors_simple; 
            Simply loads embeddings, does not train them from scratch 
        dataset: Object from the dataset class
        suffix: String, which specific instance of the dataset we're using 
        attributes: List of attributes we want to create embeddings for
        random_seed: Number representing the random seed for the embeddings
        
    Returns:
        Hierarchy from the Hierarchy class
    """
    
    distance_matrix = get_concept_distances(embedding_method,dataset,suffix,attributes,random_seed)    
    dendrogram = hierarchy_method(distance_matrix)
    h = Hierarchy()
    h.from_array(dendrogram,attributes)
    
    return h
