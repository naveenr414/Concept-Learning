{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83e508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c42d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4286b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:10:37.361923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from src.dataset import *\n",
    "from src.concept_vectors import *\n",
    "from src.util import *\n",
    "from src.plots import *\n",
    "from src.hierarchy import *\n",
    "from src.metrics import *\n",
    "from src.models import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae96cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3325ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CUB_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58c4fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n",
      "447\n",
      "407\n"
     ]
    }
   ],
   "source": [
    "for suffix in [\"\",\"_image_robustness\",\"_model_responsiveness\"]:\n",
    "    print(np.sum(load_label_vectors_simple(dataset.get_attributes()[0],dataset,suffix,42)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11935d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent dim 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/homes/njr61/main_code/src/models.py:228: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  images = np.array([file_to_numpy(i) for i in all_files])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 5678.0908 - reconstruction_loss: 2838.9517 - kl_loss: 0.1575 - concept_loss: 2838.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/homes/njr61/main_code/src/models.py:266: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_images = resize_cub(np.array(all_images))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step\n"
     ]
    }
   ],
   "source": [
    "train_VAE(dataset,\"\",42,save_location=\"\", latent_dim=2,epochs=1,concept_alignment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ba9cae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.67367435,  0.2746278 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_vae_vectors_simple(\"has_back_color::black\",CUB_Dataset(),\"_image_responsiveness\",seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ba581c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1396388 ,  0.19243965, -0.42658675,  0.01701454, -0.32708898,\n",
       "         0.7208395 ,  0.38758543,  0.07034683,  0.21086532,  0.5162337 ,\n",
       "         0.37147635, -0.01094094, -0.21870965,  0.45760262, -0.27087864,\n",
       "        -0.00768346, -0.66996974,  0.14430285, -0.43691167, -0.85338527,\n",
       "         0.06586748, -0.22222969, -0.3834473 , -0.6014196 , -0.4063005 ,\n",
       "         0.45655298, -0.00275847, -0.18300647,  0.19964525, -0.69305444,\n",
       "         0.37549675, -0.5941823 , -0.61327386, -0.11705576, -0.09494688,\n",
       "        -0.10341191, -0.09245952,  0.31608596,  0.02900577, -0.53867567,\n",
       "        -0.2669893 ,  0.16547063, -0.44882005, -0.27444395, -0.03798074,\n",
       "        -0.15899993,  0.5672046 , -0.67011654, -0.17625827,  0.61872476,\n",
       "         0.3530683 , -0.44659752, -0.12664387, -0.9338273 , -0.333057  ,\n",
       "        -0.2857629 ,  0.21944374, -0.06597994,  0.26274833,  0.25763166,\n",
       "         0.19009157, -0.10071413, -0.25036108, -0.73016727,  0.0170529 ,\n",
       "        -0.23975375, -0.6254666 ,  0.5353975 ,  0.12752998,  0.18596786,\n",
       "         0.25102085, -1.0193615 ,  0.2210036 ,  0.5061734 , -0.41895577,\n",
       "        -0.80136704, -0.36711568,  0.7984885 , -0.49918503, -0.23156746,\n",
       "         0.17606582, -0.02785218,  0.39788958, -0.23849376, -0.19284952,\n",
       "         1.0585587 ,  0.40210786, -0.4993961 ,  0.2772578 , -0.22791389,\n",
       "        -0.9675088 ,  0.7917452 , -0.38006327, -0.6509893 ,  0.6220273 ,\n",
       "        -0.41721046,  0.24158077, -0.49641186,  0.0046475 ,  0.52681696,\n",
       "         0.17128856,  0.32046577, -0.38664517,  0.1247111 ,  0.6342775 ,\n",
       "         0.5834933 ,  0.8822819 , -0.00936345, -0.19828033,  0.32516336,\n",
       "         0.6842426 , -0.06814035]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_vae_concept_vectors_simple(\"has_back_color::black\",CUB_Dataset(),\"\",seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2f950a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/CUB_ige_robustness/preprocessed/train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9219/360327088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_concept2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"_ige_robustness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/concept_vectors.py\u001b[0m in \u001b[0;36mcreate_concept2vec\u001b[0;34m(dataset, suffix, seed, embedding_size, num_epochs, dataset_size, initial_embedding)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mSkipGram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_skipgram_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/dataset.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, seed, suffix, train)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_pkl_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/CUB_ige_robustness/preprocessed/train.pkl'"
     ]
    }
   ],
   "source": [
    "create_concept2vec(dataset,\"_image_robustness\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b27cd2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08862728, -0.22278228, -0.33395338,  0.3019868 , -0.01222411,\n",
       "         0.29873982,  0.35323834,  0.1366382 , -0.25656658,  0.324455  ,\n",
       "         0.17890984, -0.32997307, -0.01974672, -0.2481588 , -0.2735666 ,\n",
       "         0.2445152 ,  0.15376762,  0.3406197 ,  0.02418177, -0.03433285,\n",
       "         0.26493436, -0.0081104 ,  0.28707227, -0.31152803, -0.20898055,\n",
       "        -0.19636793, -0.23137163,  0.26689827,  0.21054439,  0.27037305,\n",
       "         0.14287092, -0.04401413]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_concept2vec_vectors_simple(dataset.get_attributes()[0],dataset,\"\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221a5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_vectors(dataset.get_attributes()[0:1],dataset,\"_image_robustness\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af295cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['random500_0', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['random500_1', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:TCAV will 4 params\n",
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:running 2 params\n",
      "INFO:tensorflow:Running param 0 of 2\n",
      "INFO:tensorflow:running zebra ['has_bill_shape::dagger', 'random500_0']\n",
      "INFO:tensorflow:./results/activations/acts_has_bill_shape::dagger_block4_conv1 does not exist, Making one...\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_random500_0_block4_conv1 shape (50, 28, 28, 512)\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_zebra_block4_conv1 shape (5, 28, 28, 512)\n",
      "INFO:tensorflow:Training CAV ['has_bill_shape::dagger', 'random500_0'] - block4_conv1 alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'has_bill_shape::dagger': 1.0, 'random500_0': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:CAV accuracies: {'has_bill_shape::dagger': 1.0, 'random500_0': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:Running param 1 of 2\n",
      "INFO:tensorflow:running zebra ['has_bill_shape::dagger', 'random500_1']\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_has_bill_shape::dagger_block4_conv1 shape (10, 28, 28, 512)\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_random500_1_block4_conv1 shape (50, 28, 28, 512)\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_zebra_block4_conv1 shape (5, 28, 28, 512)\n",
      "INFO:tensorflow:Training CAV ['has_bill_shape::dagger', 'random500_1'] - block4_conv1 alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'has_bill_shape::dagger': 1.0, 'random500_1': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:CAV accuracies: {'has_bill_shape::dagger': 1.0, 'random500_1': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:Done running 2 params. Took 18.039724826812744 seconds...\n"
     ]
    }
   ],
   "source": [
    "create_tcav_dataset(dataset.get_attributes()[0],CUB_Dataset(),\n",
    "                            2,10,\n",
    "                            seed=42,suffix=\"_image_robustness\",model_name=\"VGG16\",bottlenecks=['block4_conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dfc7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_method = combine_embeddings_concatenate(load_label_vectors_simple,load_tcav_vectors_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f1ecc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_method(dataset.get_attributes()[0],CUB_Dataset(),\"_image_robustness\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b9fd2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_label_vectors_simple(dataset.get_attributes()[0],dataset,\"_model_robustness\",42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
