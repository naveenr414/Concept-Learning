{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83e508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c42d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4286b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 18:18:16.309477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from src.dataset import *\n",
    "from src.concept_vectors import *\n",
    "from src.util import *\n",
    "from src.plots import *\n",
    "from src.hierarchy import *\n",
    "from src.metrics import *\n",
    "from src.models import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae96cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image, ImageOps\n",
    "import pickle\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3325ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CUB_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58c4fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n",
      "447\n",
      "407\n"
     ]
    }
   ],
   "source": [
    "for suffix in [\"\",\"_image_robustness\",\"_model_responsiveness\"]:\n",
    "    print(np.sum(load_label_vectors_simple(dataset.get_attributes()[0],dataset,suffix,42)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11935d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent dim 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/homes/njr61/main_code/src/models.py:228: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  images = np.array([file_to_numpy(i) for i in all_files])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 5678.0908 - reconstruction_loss: 2838.9517 - kl_loss: 0.1575 - concept_loss: 2838.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/homes/njr61/main_code/src/models.py:266: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_images = resize_cub(np.array(all_images))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step\n"
     ]
    }
   ],
   "source": [
    "train_VAE(dataset,\"\",42,save_location=\"\", latent_dim=2,epochs=1,concept_alignment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ba9cae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.67367435,  0.2746278 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_vae_vectors_simple(\"has_back_color::black\",CUB_Dataset(),\"_image_responsiveness\",seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ba581c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1396388 ,  0.19243965, -0.42658675,  0.01701454, -0.32708898,\n",
       "         0.7208395 ,  0.38758543,  0.07034683,  0.21086532,  0.5162337 ,\n",
       "         0.37147635, -0.01094094, -0.21870965,  0.45760262, -0.27087864,\n",
       "        -0.00768346, -0.66996974,  0.14430285, -0.43691167, -0.85338527,\n",
       "         0.06586748, -0.22222969, -0.3834473 , -0.6014196 , -0.4063005 ,\n",
       "         0.45655298, -0.00275847, -0.18300647,  0.19964525, -0.69305444,\n",
       "         0.37549675, -0.5941823 , -0.61327386, -0.11705576, -0.09494688,\n",
       "        -0.10341191, -0.09245952,  0.31608596,  0.02900577, -0.53867567,\n",
       "        -0.2669893 ,  0.16547063, -0.44882005, -0.27444395, -0.03798074,\n",
       "        -0.15899993,  0.5672046 , -0.67011654, -0.17625827,  0.61872476,\n",
       "         0.3530683 , -0.44659752, -0.12664387, -0.9338273 , -0.333057  ,\n",
       "        -0.2857629 ,  0.21944374, -0.06597994,  0.26274833,  0.25763166,\n",
       "         0.19009157, -0.10071413, -0.25036108, -0.73016727,  0.0170529 ,\n",
       "        -0.23975375, -0.6254666 ,  0.5353975 ,  0.12752998,  0.18596786,\n",
       "         0.25102085, -1.0193615 ,  0.2210036 ,  0.5061734 , -0.41895577,\n",
       "        -0.80136704, -0.36711568,  0.7984885 , -0.49918503, -0.23156746,\n",
       "         0.17606582, -0.02785218,  0.39788958, -0.23849376, -0.19284952,\n",
       "         1.0585587 ,  0.40210786, -0.4993961 ,  0.2772578 , -0.22791389,\n",
       "        -0.9675088 ,  0.7917452 , -0.38006327, -0.6509893 ,  0.6220273 ,\n",
       "        -0.41721046,  0.24158077, -0.49641186,  0.0046475 ,  0.52681696,\n",
       "         0.17128856,  0.32046577, -0.38664517,  0.1247111 ,  0.6342775 ,\n",
       "         0.5834933 ,  0.8822819 , -0.00936345, -0.19828033,  0.32516336,\n",
       "         0.6842426 , -0.06814035]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_vae_concept_vectors_simple(\"has_back_color::black\",CUB_Dataset(),\"\",seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2f950a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/CUB_ige_robustness/preprocessed/train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9219/360327088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_concept2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"_ige_robustness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/concept_vectors.py\u001b[0m in \u001b[0;36mcreate_concept2vec\u001b[0;34m(dataset, suffix, seed, embedding_size, num_epochs, dataset_size, initial_embedding)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mSkipGram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_skipgram_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/dataset.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, seed, suffix, train)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_pkl_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/CUB_ige_robustness/preprocessed/train.pkl'"
     ]
    }
   ],
   "source": [
    "create_concept2vec(dataset,\"_image_robustness\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b27cd2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08862728, -0.22278228, -0.33395338,  0.3019868 , -0.01222411,\n",
       "         0.29873982,  0.35323834,  0.1366382 , -0.25656658,  0.324455  ,\n",
       "         0.17890984, -0.32997307, -0.01974672, -0.2481588 , -0.2735666 ,\n",
       "         0.2445152 ,  0.15376762,  0.3406197 ,  0.02418177, -0.03433285,\n",
       "         0.26493436, -0.0081104 ,  0.28707227, -0.31152803, -0.20898055,\n",
       "        -0.19636793, -0.23137163,  0.26689827,  0.21054439,  0.27037305,\n",
       "         0.14287092, -0.04401413]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_concept2vec_vectors_simple(dataset.get_attributes()[0],dataset,\"\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221a5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_vectors(dataset.get_attributes()[0:1],dataset,\"_image_robustness\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b4624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['random500_0', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['random500_1', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:TCAV will 4 params\n",
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:block4_conv1 ['has_bill_shape::dagger', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:running 2 params\n",
      "INFO:tensorflow:Running param 0 of 2\n",
      "INFO:tensorflow:running zebra ['has_bill_shape::dagger', 'random500_0']\n",
      "INFO:tensorflow:./results/activations/acts_has_bill_shape::dagger_block4_conv1 does not exist, Making one...\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_random500_0_block4_conv1 shape (50, 28, 28, 512)\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_zebra_block4_conv1 shape (5, 28, 28, 512)\n",
      "INFO:tensorflow:Training CAV ['has_bill_shape::dagger', 'random500_0'] - block4_conv1 alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'has_bill_shape::dagger': 1.0, 'random500_0': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:CAV accuracies: {'has_bill_shape::dagger': 1.0, 'random500_0': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:Running param 1 of 2\n",
      "INFO:tensorflow:running zebra ['has_bill_shape::dagger', 'random500_1']\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_has_bill_shape::dagger_block4_conv1 shape (10, 28, 28, 512)\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_random500_1_block4_conv1 shape (50, 28, 28, 512)\n",
      "INFO:tensorflow:Loaded ./results/activations/acts_zebra_block4_conv1 shape (5, 28, 28, 512)\n",
      "INFO:tensorflow:Training CAV ['has_bill_shape::dagger', 'random500_1'] - block4_conv1 alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'has_bill_shape::dagger': 1.0, 'random500_1': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:CAV accuracies: {'has_bill_shape::dagger': 1.0, 'random500_1': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:Done running 2 params. Took 18.039724826812744 seconds...\n"
     ]
    }
   ],
   "source": [
    "create_tcav_dataset(dataset.get_attributes()[0],CUB_Dataset(),\n",
    "                            2,10,\n",
    "                            seed=42,suffix=\"_image_robustness\",model_name=\"VGG16\",bottlenecks=['block4_conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a96d0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_method = combine_embeddings_concatenate(load_label_vectors_simple,load_tcav_vectors_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e6541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_method(dataset.get_attributes()[0],CUB_Dataset(),\"_image_robustness\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b9fd2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_label_vectors_simple(dataset.get_attributes()[0],dataset,\"_model_robustness\",42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7f13482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:44:44.117393: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 4s 5ms/step - loss: 0.6804\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5956\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5716\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5558\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5379\n",
      "500/500 [==============================] - 4s 6ms/step - loss: 0.6848\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.6059\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5863\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5722\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5660\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.6932\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.6932\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.6932\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.6931\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.6932\n",
      "500/500 [==============================] - 4s 6ms/step - loss: 0.6804\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5956\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5716\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5558\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5379\n",
      "500/500 [==============================] - 4s 6ms/step - loss: 0.6804\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5956\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5716\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5558\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5379\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.6787\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5977\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.5733\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5623\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.5496\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.6818\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.6097\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.5836\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.5722\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.5701\n",
      "500/500 [==============================] - 5s 7ms/step - loss: 0.6932\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.6931\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.6931\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 0.6933\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.6933\n",
      "500/500 [==============================] - 8s 12ms/step - loss: 0.6787\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.5977\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5733\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.5623\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.5496\n",
      "500/500 [==============================] - 5s 8ms/step - loss: 0.6787\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5977\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.5733\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.5623\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.5496\n",
      "500/500 [==============================] - 8s 13ms/step - loss: 0.6847\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.6115\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5670\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.5648\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.5529\n",
      "500/500 [==============================] - 8s 14ms/step - loss: 0.6864\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.6190\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.5845\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.5747\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.5681\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.6932\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.6931\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.6933\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.6933\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.6933\n",
      "500/500 [==============================] - 5s 8ms/step - loss: 0.6847\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.6115\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5670\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.5648\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.5529\n",
      "500/500 [==============================] - 8s 12ms/step - loss: 0.6847\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.6115\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.5670\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.5648\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5529\n"
     ]
    }
   ],
   "source": [
    "for seed in [43,44,45]:\n",
    "    for suffix in [\"\",\"_image_robustness\",\"_image_responsiveness\",\n",
    "                   \"_model_robustness\",\"_model_responsiveness\"]:\n",
    "        create_concept2vec(CUB_Dataset(),suffix,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b180f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 370, 3)\n",
      "WARNING:tensorflow:5 out of the last 2504 calls to <function Model.make_train_function.<locals>.train_function at 0x7f7da42550e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 10s 10s/step - loss: 5678.7134 - reconstruction_loss: 2839.3328 - kl_loss: 0.1664 - concept_loss: 2839.2141\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30532/4129993693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_VAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUB_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"_model_robustness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconcept_alignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/models.py\u001b[0m in \u001b[0;36mtrain_VAE\u001b[0;34m(dataset, suffix, seed, save_location, latent_dim, epochs, concept_alignment)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/models/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0msave_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconcept_alignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcept_alignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/models.py\u001b[0m in \u001b[0;36msave_vae\u001b[0;34m(model, dataset, suffix, seed, concept_alignment)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_cub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_cub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/main_code/src/util.py\u001b[0m in \u001b[0;36mfile_to_numpy\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \"\"\"\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/auto/homes/njr61/environments/mambaforge/envs/concepts/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/environments/mambaforge/envs/concepts/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/environments/mambaforge/envs/concepts/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_VAE(CUB_Dataset(),\"_model_robustness\",43,epochs=1,latent_dim=4,concept_alignment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb374b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "suffix = \"_image_responsiveness\"\n",
    "dataset = CUB_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dataset.get_data(seed=seed,suffix=suffix)\n",
    "all_files = ['dataset/'+i['img_path'] for i in all_data]\n",
    "images = np.array([file_to_numpy(i) for i in all_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51706c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_files[i] for i in range(len(images)) if len(images[i].shape) != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce39673e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b27dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 18:21:05.021133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 18:21:05.030844: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'images' must have either 3 or 4 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10505/3780176889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10505/3780176889.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/auto/homes/njr61/environments/mambaforge/envs/concepts/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/njr61/environments/mambaforge/envs/concepts/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1443\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\'images\\' must have either 3 or 4 dimensions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'images' must have either 3 or 4 dimensions."
     ]
    }
   ],
   "source": [
    "c = np.array([tf.image.resize(i,(64,64)) for i in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd1cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['dataset/CUB{}/images/CUB_200_2011/images/093.Clark_Nutcracker/Clark_Nutcracker_0020_85099.jpg', \n",
    "        'dataset/CUB{}/images/CUB_200_2011/images/063.Ivory_Gull/Ivory_Gull_0040_49180.jpg', \n",
    "        'dataset/CUB{}/images/CUB_200_2011/images/066.Western_Gull/Western_Gull_0002_54825.jpg', \n",
    "        'dataset/CUB{}/images/CUB_200_2011/images/025.Pelagic_Cormorant/Pelagic_Cormorant_0022_23802.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1186d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Image.open('dataset/CUB_image_robustness/images/CUB_200_2011/images/093.Clark_Nutcracker/Clark_Nutcracker_0020_85099.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5301ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77c12ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suffix in [\"\",\"_image_robustness\",\"_image_responsiveness\"]:\n",
    "    for data_point in data:\n",
    "        img_loc = data_point.format(suffix)\n",
    "        a = Image.open(img_loc)\n",
    "        a = a.convert(\"RGB\")\n",
    "        a.save(img_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2329e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_vectors(CUB_Dataset().get_attributes()[0:1],CUB_Dataset(),\"\",43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "546dd0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"has_bill_shape::dagger\" \"has_bill_shape::hooked_seabird\" \"has_bill_shape::all-purpose\" \"has_bill_shape::cone\" \"has_wing_color::brown\" \"has_wing_color::grey\" \"has_wing_color::yellow\" \"has_wing_color::black\" \"has_wing_color::white\" \"has_wing_color::buff\" \"has_upperparts_color::brown\" \"has_upperparts_color::grey\" \"has_upperparts_color::yellow\" \"has_upperparts_color::black\" \"has_upperparts_color::white\" \"has_upperparts_color::buff\" \"has_underparts_color::brown\" \"has_underparts_color::grey\" \"has_underparts_color::yellow\" \"has_underparts_color::black\" \"has_underparts_color::white\" \"has_underparts_color::buff\" \"has_breast_pattern::solid\" \"has_breast_pattern::striped\" \"has_breast_pattern::multi-colored\" \"has_back_color::brown\" \"has_back_color::grey\" \"has_back_color::yellow\" \"has_back_color::black\" \"has_back_color::white\" \"has_back_color::buff\" \"has_tail_shape::notched_tail\" \"has_upper_tail_color::brown\" \"has_upper_tail_color::grey\" \"has_upper_tail_color::black\" \"has_upper_tail_color::white\" \"has_upper_tail_color::buff\" \"has_head_pattern::eyebrow\" \"has_head_pattern::plain\" \"has_breast_color::brown\" \"has_breast_color::grey\" \"has_breast_color::yellow\" \"has_breast_color::black\" \"has_breast_color::white\" \"has_breast_color::buff\" \"has_throat_color::grey\" \"has_throat_color::yellow\" \"has_throat_color::black\" \"has_throat_color::white\" \"has_throat_color::buff\" \"has_eye_color::black\" \"has_bill_length::about_the_same_as_head\" \"has_bill_length::shorter_than_head\" \"has_forehead_color::blue\" \"has_forehead_color::brown\" \"has_forehead_color::grey\" \"has_forehead_color::yellow\" \"has_forehead_color::black\" \"has_forehead_color::white\" \"has_under_tail_color::brown\" \"has_under_tail_color::grey\" \"has_under_tail_color::black\" \"has_under_tail_color::white\" \"has_under_tail_color::buff\" \"has_nape_color::brown\" \"has_nape_color::grey\" \"has_nape_color::yellow\" \"has_nape_color::black\" \"has_nape_color::white\" \"has_nape_color::buff\" \"has_belly_color::brown\" \"has_belly_color::grey\" \"has_belly_color::yellow\" \"has_belly_color::black\" \"has_belly_color::white\" \"has_belly_color::buff\" \"has_wing_shape::rounded-wings\" \"has_wing_shape::pointed-wings\" \"has_size::small_(5_-_9_in)\" \"has_size::medium_(9_-_16_in)\" \"has_size::very_small_(3_-_5_in)\" \"has_shape::duck-like\" \"has_shape::perching-like\" \"has_back_pattern::solid\" \"has_back_pattern::striped\" \"has_back_pattern::multi-colored\" \"has_tail_pattern::solid\" \"has_tail_pattern::striped\" \"has_tail_pattern::multi-colored\" \"has_belly_pattern::solid\" \"has_primary_color::brown\" \"has_primary_color::grey\" \"has_primary_color::yellow\" \"has_primary_color::black\" \"has_primary_color::white\" \"has_primary_color::buff\" \"has_leg_color::grey\" \"has_leg_color::black\" \"has_leg_color::buff\" \"has_bill_color::grey\" \"has_bill_color::black\" \"has_bill_color::buff\" \"has_crown_color::blue\" \"has_crown_color::brown\" \"has_crown_color::grey\" \"has_crown_color::yellow\" \"has_crown_color::black\" \"has_crown_color::white\" \"has_wing_pattern::solid\" \"has_wing_pattern::spotted\" \"has_wing_pattern::striped\" \"has_wing_pattern::multi-colored\"\n"
     ]
    }
   ],
   "source": [
    "attributes = CUB_Dataset().get_attributes()\n",
    "attributes = ['\"{}\"'.format(i) for i in attributes]\n",
    "print(\" \".join(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831d233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
