{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd0e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011d6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4171c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 12:03:25.125819: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import *\n",
    "from src.concept_vectors import *\n",
    "from src.util import *\n",
    "from src.hierarchy import *\n",
    "from src.metrics import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from src.create_vectors import *\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539c3cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.system(\"export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d7ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [43,44,45]\n",
    "vector_method = [load_cem_vectors_simple,load_concept2vec_vectors_simple,load_label_vectors_simple,load_tcav_vectors_simple]\n",
    "vector_names = [\"CEM\",\"Concept2Vec\",\"Label\",\"TCAV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7152c2",
   "metadata": {},
   "source": [
    "## Debugging: Check which TCAV Vectors are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5af6e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CUB_Dataset()\n",
    "attributes = dataset.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "577eebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_exists(attribute_name,suffix,seed):\n",
    "    attribute_name = attribute_name.replace(\" \",\"_\")\n",
    "    folder_name = \"results/bases/tcav/{}{}/{}/\".format(dataset.experiment_name,suffix,seed)\n",
    "    for i in range(3):\n",
    "        file_name = \"{}_{}_{}-random500_{}-block4_conv1-linear-0.1.pkl\".format(attribute_name,seed,suffix,i)\n",
    "\n",
    "        if not os.path.exists(folder_name + file_name):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1ec859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in attributes:\n",
    "    for seed in [43,44,45]:\n",
    "        for suffix in ['','_image_robustness','_image_responsiveness']:\n",
    "            attribute_exists(attribute,suffix,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdafd0",
   "metadata": {},
   "source": [
    "## Evaluate All Vectors MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d0a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST_Dataset()\n",
    "attributes = dataset.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dd9a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/concept_hierarchies/src/metrics.py:363: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_concept_embeddings = np.array([embedding_method(i,dataset,\"\",seed=seed) for i in dataset.get_attributes()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truthfulness: (0.8666666666666667, 0.1885618083164127)\n",
      "Image Robustness: (0.19999999999999998, 0.08164965809277264)\n",
      "Image Responsiveness: (0.9500000000000001, 0.07071067811865477)\n",
      "Stability: (0.1333333333333333, 0.09428090415820632)\n",
      "Method CEM: {'Truthfulness': (0.8666666666666667, 0.1885618083164127), 'Image Robustness': (0.19999999999999998, 0.08164965809277264), 'Image Responsiveness': (0.9500000000000001, 0.07071067811865477), 'Stability': (0.1333333333333333, 0.09428090415820632)}\n",
      "Computing Concept2Vec\n",
      "Truthfulness: (1.0, 0.0)\n",
      "Image Robustness: (0.0, 0.0)\n",
      "Image Responsiveness: (0.9500000000000001, 0.04082482904638629)\n",
      "Stability: (0.0, 0.0)\n",
      "Method Concept2Vec: {'Truthfulness': (1.0, 0.0), 'Image Robustness': (0.0, 0.0), 'Image Responsiveness': (0.9500000000000001, 0.04082482904638629), 'Stability': (0.0, 0.0)}\n",
      "Computing Label\n",
      "Truthfulness: (1.0, 0.0)\n",
      "Image Robustness: (0.0, 0.0)\n",
      "Image Responsiveness: (1.0, 0.0)\n",
      "Stability: (0.0, 0.0)\n",
      "Method Label: {'Truthfulness': (1.0, 0.0), 'Image Robustness': (0.0, 0.0), 'Image Responsiveness': (1.0, 0.0), 'Stability': (0.0, 0.0)}\n",
      "Computing TCAV\n",
      "Truthfulness: (1.0, 0.0)\n",
      "Image Robustness: (0.8833333333333334, 0.062360956446232324)\n",
      "Image Responsiveness: (0.9500000000000001, 0.04082482904638629)\n",
      "Stability: (0.0, 0.0)\n",
      "Method TCAV: {'Truthfulness': (1.0, 0.0), 'Image Robustness': (0.8833333333333334, 0.062360956446232324), 'Image Responsiveness': (0.9500000000000001, 0.04082482904638629), 'Stability': (0.0, 0.0)}\n"
     ]
    }
   ],
   "source": [
    "for method,name in zip(vector_method,vector_names):\n",
    "    print(\"Computing {}\".format(name))\n",
    "    start = time.time()\n",
    "\n",
    "    results = compute_all_metrics(method,\n",
    "                                        dataset,\n",
    "                                        attributes,\n",
    "                                        seeds)\n",
    "    print(\"Method {}: {}\".format(name,results))\n",
    "    \n",
    "    name_lower = name.lower()\n",
    "    w = open(\"results/evaluation/{}_{}.txt\".format(dataset.experiment_name,name_lower),\"w\")\n",
    "    for key in results:\n",
    "        w.write(\"{}: {}\\n\".format(key,results[key]))\n",
    "    w.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b75c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_distances = np.zeros((len(attributes),len(attributes)))\n",
    "for i, attribute_1 in enumerate(attributes):\n",
    "    for j, attribute_2 in enumerate(attributes):\n",
    "        baseline_distances[i][j] = (1-int(attribute_1[0] == attribute_2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75567fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_by_method_mnist = {}\n",
    "for function,name in zip(vector_method,vector_names):\n",
    "    h_list = [flat_distance_to_square(get_concept_distances(function,MNIST_Dataset(),'',MNIST_Dataset().get_attributes(),seed)) for seed in [43,44,45]]\n",
    "    distance_by_method_mnist[name] = [embedding_distance(h,baseline_distances,k=1) for h in h_list]\n",
    "    distance_by_method_mnist[name] = (np.mean(distance_by_method_mnist[name]),np.std(distance_by_method_mnist[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a562fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(distance_by_method_mnist,open('results/evaluation/ablation/distance_mnist.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce14e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = [load_label_vectors_simple,load_cem_vectors_simple,load_concept2vec_vectors_simple,load_tcav_vectors_simple]\n",
    "name_list = ['label','cem','concept2vec','tcav']\n",
    "dataset = MNIST_Dataset()\n",
    "\n",
    "agreement_by_method = {}\n",
    "\n",
    "for method,name in zip(method_list,name_list):\n",
    "    agreement_by_method[name] = []\n",
    "\n",
    "    for seed in [43,44,45]:\n",
    "        all_vectors = [np.mean(np.array(method(a,dataset,\"\",seed)),axis=0) for a in dataset.get_attributes()]\n",
    "        all_vectors = np.array(all_vectors)\n",
    "\n",
    "        closest_vectors = []\n",
    "\n",
    "        # Iterate through each vector in the array\n",
    "        for i in range(len(all_vectors)):\n",
    "            current_vector = all_vectors[i]\n",
    "            \n",
    "            # Compute cosine similarity with all other vectors\n",
    "            similarities = [1 - cosine(current_vector, other_vector) for other_vector in all_vectors]\n",
    "\n",
    "            # Find the index of the vector with the maximum cosine similarity (excluding the current vector)\n",
    "            closest_index = np.argmax(similarities[:i] + similarities[i+1:])  # Exclude the current vector\n",
    "            \n",
    "            if closest_index >= i:\n",
    "                closest_index += 1\n",
    "\n",
    "            # Append the closest vector to the list\n",
    "            closest_vectors.append(closest_index)\n",
    "\n",
    "        # Convert the list to a NumPy array if needed\n",
    "        closest_vectors = np.array(closest_vectors)\n",
    "        correct_vectors = []\n",
    "\n",
    "        for i in range(0,len(dataset.get_attributes()),2):\n",
    "            correct_vectors.append(i+1)\n",
    "            correct_vectors.append(i)\n",
    "        \n",
    "        agreement_by_method[name].append(float(np.sum(np.array(closest_vectors) == np.array(correct_vectors))/len(correct_vectors)))\n",
    "json.dump(agreement_by_method,open('results/evaluation/ablation/agreement_mnist.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11209b50",
   "metadata": {},
   "source": [
    "## Evaluate all Vectors CUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c026bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CUB_Dataset()\n",
    "attributes = dataset.get_attributes()\n",
    "seeds = [43,44,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b78ba214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TCAV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/concept_hierarchies/src/metrics.py:363: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_concept_embeddings = np.array([embedding_method(i,dataset,\"\",seed=seed) for i in dataset.get_attributes()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truthfulness: (0.0755952380952381, 0.008908708063747483)\n",
      "Image Robustness: (0.9970238095238096, 0.002430049347999176)\n",
      "Image Responsiveness: (0.9880952380952381, 0.004860098695998397)\n",
      "Stability: (0.9890873015873017, 0.0037119616932281036)\n",
      "Method TCAV: {'Truthfulness': (0.0755952380952381, 0.008908708063747483), 'Image Robustness': (0.9970238095238096, 0.002430049347999176), 'Image Responsiveness': (0.9880952380952381, 0.004860098695998397), 'Stability': (0.9890873015873017, 0.0037119616932281036)}\n",
      "Computing Label\n",
      "Truthfulness: (0.7321428571428571, 0.0)\n",
      "Image Robustness: (0.0267857142857143, 0.0)\n",
      "Image Responsiveness: (0.9672619047619048, 0.0)\n",
      "Stability: (0.0, 0.0)\n",
      "Method Label: {'Truthfulness': (0.7321428571428571, 0.0), 'Image Robustness': (0.0267857142857143, 0.0), 'Image Responsiveness': (0.9672619047619048, 0.0), 'Stability': (0.0, 0.0)}\n",
      "Computing Concept2Vec\n",
      "Truthfulness: (0.41130952380952385, 0.012400396819047418)\n",
      "Image Robustness: (0.6865079365079364, 0.018559808466140564)\n",
      "Image Responsiveness: (0.9781746031746031, 0.007811515748027595)\n",
      "Stability: (0.7083333333333334, 0.015934899210524805)\n",
      "Method Concept2Vec: {'Truthfulness': (0.41130952380952385, 0.012400396819047418), 'Image Robustness': (0.6865079365079364, 0.018559808466140564), 'Image Responsiveness': (0.9781746031746031, 0.007811515748027595), 'Stability': (0.7083333333333334, 0.015934899210524805)}\n",
      "Computing CEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/concept_hierarchies/src/metrics.py:363: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_concept_embeddings = np.array([embedding_method(i,dataset,\"\",seed=seed) for i in dataset.get_attributes()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truthfulness: (0.05535714285714286, 0.0025253813613805246)\n",
      "Image Robustness: (0.9751984126984127, 0.01148396518133952)\n",
      "Image Responsiveness: (0.9771825396825397, 0.008534052844288337)\n",
      "Stability: (0.9722222222222222, 0.0037119616932281036)\n",
      "Method CEM: {'Truthfulness': (0.05535714285714286, 0.0025253813613805246), 'Image Robustness': (0.9751984126984127, 0.01148396518133952), 'Image Responsiveness': (0.9771825396825397, 0.008534052844288337), 'Stability': (0.9722222222222222, 0.0037119616932281036)}\n"
     ]
    }
   ],
   "source": [
    "for method,name in zip(vector_method[::-1],vector_names[::-1]):\n",
    "    print(\"Computing {}\".format(name))\n",
    "    start = time.time()\n",
    "\n",
    "    results = compute_all_metrics(method,\n",
    "                                        dataset,\n",
    "                                        attributes,\n",
    "                                        seeds)\n",
    "    print(\"Method {}: {}\".format(name,results))\n",
    "    \n",
    "    name_lower = name.lower()\n",
    "    w = open(\"results/evaluation/{}_{}.txt\".format(dataset.experiment_name,name_lower),\"w\")\n",
    "    for key in results:\n",
    "        w.write(\"{}: {}\\n\".format(key,results[key]))\n",
    "    w.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_distances_color = np.zeros((len(attributes),len(attributes)))\n",
    "for i, attribute_1 in enumerate(attributes):\n",
    "    for j, attribute_2 in enumerate(attributes):\n",
    "        baseline_distances_color[i][j] = (1-int(attribute_1.split(\"::\")[1] == attribute_2.split(\"::\")[1])) + abs(random.random()/100)*int(attribute_1 != attribute_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_by_method_cub = {}\n",
    "for function,name in zip(vector_method,vector_names):\n",
    "    h_list = [flat_distance_to_square(get_concept_distances(function,cub,'',cub_attributes,seed)) for seed in [43,44,45]]\n",
    "    distance_by_method_cub[name] = [embedding_distance(h,baseline_distances_color,k=3) for h in h_list]\n",
    "    distance_by_method_cub[name] = (np.mean(distance_by_method_cub[name]),np.std(distance_by_method_cub[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(distance_by_method_cub,open('results/evaluation/ablation/distance_cub_second_part.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pairs = get_top_k_pairs(baseline_distances_color,k=3)\n",
    "top_pairs = [(attributes[i[0]],attributes[i[1]]) for i in top_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b45e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_top_pairs = get_top_k_pairs(flat_distance_to_square(get_concept_distances(load_label_vectors_simple,dataset,'',attributes,43)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_top_pairs = [(attributes[i[0]],attributes[i[1]]) for i in our_top_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9caccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_distances_attribute = np.zeros((len(attributes),len(attributes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, attribute_1 in enumerate(attributes):\n",
    "    for j, attribute_2 in enumerate(attributes):\n",
    "        baseline_distances_attribute[i][j] = (1-int(attribute_1.split(\"::\")[0] == attribute_2.split(\"::\")[0])) + abs(np.random.random()/100)*int(attribute_1 != attribute_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b603b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_by_method_cub = {}\n",
    "for function,name in zip(vector_method,vector_names):\n",
    "    h_list = [flat_distance_to_square(get_concept_distances(function,cub,'',cub_attributes,seed)) for seed in [43,44,45]]\n",
    "    distance_by_method_cub[name] = [embedding_distance(h,baseline_distances_attribute,k=3) for h in h_list]\n",
    "    distance_by_method_cub[name] = (np.mean(distance_by_method_cub[name]),np.std(distance_by_method_cub[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(distance_by_method_cub,open('results/evaluation/ablation/distance_cub_first_part.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4eef3a",
   "metadata": {},
   "source": [
    "## Evalaute all Vectors DSprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59fa35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DSprites_Dataset()\n",
    "attributes = dataset.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "572b96fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TCAV\n",
      "Truthfulness: (0.30370370370370375, 0.013857990321384989)\n",
      "Image Robustness: (0.6049382716049382, 0.04860498687661615)\n",
      "Image Responsiveness: (0.8148148148148148, 0.05237828008789238)\n",
      "Stability: (0.4444444444444444, 0.04000457221239422)\n",
      "Method TCAV: {'Truthfulness': (0.30370370370370375, 0.013857990321384989), 'Image Robustness': (0.6049382716049382, 0.04860498687661615), 'Image Responsiveness': (0.8148148148148148, 0.05237828008789238), 'Stability': (0.4444444444444444, 0.04000457221239422)}\n",
      "Computing Label\n",
      "Truthfulness: (0.5, 0.0)\n",
      "Image Robustness: (0.8148148148148149, 0.0)\n",
      "Image Responsiveness: (0.7777777777777778, 0.0)\n",
      "Stability: (0.0, 0.0)\n",
      "Method Label: {'Truthfulness': (0.5, 0.0), 'Image Robustness': (0.8148148148148149, 0.0), 'Image Responsiveness': (0.7777777777777778, 0.0), 'Stability': (0.0, 0.0)}\n",
      "Computing Concept2Vec\n",
      "Truthfulness: (0.3074074074074075, 0.027715980642769932)\n",
      "Image Robustness: (0.8765432098765432, 0.04364856673991033)\n",
      "Image Responsiveness: (0.8395061728395062, 0.031475429096251756)\n",
      "Stability: (0.1666666666666667, 0.026189140043946214)\n",
      "Method Concept2Vec: {'Truthfulness': (0.3074074074074075, 0.027715980642769932), 'Image Robustness': (0.8765432098765432, 0.04364856673991033), 'Image Responsiveness': (0.8395061728395062, 0.031475429096251756), 'Stability': (0.1666666666666667, 0.026189140043946214)}\n",
      "Computing CEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/concept_hierarchies/src/metrics.py:363: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_concept_embeddings = np.array([embedding_method(i,dataset,\"\",seed=seed) for i in dataset.get_attributes()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truthfulness: (0.2703703703703704, 0.010475656017578472)\n",
      "Image Robustness: (0.7592592592592592, 0.15930231976004866)\n",
      "Image Responsiveness: (0.8765432098765432, 0.05310077325334951)\n",
      "Stability: (0.29012345679012347, 0.031475429096251756)\n",
      "Method CEM: {'Truthfulness': (0.2703703703703704, 0.010475656017578472), 'Image Robustness': (0.7592592592592592, 0.15930231976004866), 'Image Responsiveness': (0.8765432098765432, 0.05310077325334951), 'Stability': (0.29012345679012347, 0.031475429096251756)}\n"
     ]
    }
   ],
   "source": [
    "for method,name in zip(vector_method[::-1],vector_names[::-1]):\n",
    "    print(\"Computing {}\".format(name))\n",
    "    start = time.time()\n",
    "\n",
    "    results = compute_all_metrics(method,\n",
    "                                        dataset,\n",
    "                                        attributes,\n",
    "                                        seeds)\n",
    "    print(\"Method {}: {}\".format(name,results))\n",
    "    \n",
    "    name_lower = name.lower()\n",
    "    w = open(\"results/evaluation/{}_{}.txt\".format(dataset.experiment_name,name_lower),\"w\")\n",
    "    for key in results:\n",
    "        w.write(\"{}: {}\\n\".format(key,results[key]))\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823b9be",
   "metadata": {},
   "source": [
    "## Evaluate all Vectors Chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0c686a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Chexpert_Dataset()\n",
    "attributes = dataset.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6f6475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/naveenr/projects/concept_hierarchies/src/metrics.py:363: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_concept_embeddings = np.array([embedding_method(i,dataset,\"\",seed=seed) for i in dataset.get_attributes()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truthfulness: (0.4051282051282052, 0.05076664070057265)\n",
      "Image Robustness: (0.5042735042735043, 0.11530544925839355)\n",
      "Image Responsiveness: (0.7264957264957265, 0.12791991065893818)\n",
      "Stability: (0.5555555555555557, 0.06729921259839156)\n",
      "Method CEM: {'Truthfulness': (0.4051282051282052, 0.05076664070057265), 'Image Robustness': (0.5042735042735043, 0.11530544925839355), 'Image Responsiveness': (0.7264957264957265, 0.12791991065893818), 'Stability': (0.5555555555555557, 0.06729921259839156)}\n",
      "Computing Concept2Vec\n",
      "Truthfulness: (0.441025641025641, 0.06322475900481)\n",
      "Image Robustness: (0.358974358974359, 0.07548513560963974)\n",
      "Image Responsiveness: (0.7606837606837606, 0.03197997766473456)\n",
      "Stability: (0.5726495726495726, 0.052687299170675)\n",
      "Method Concept2Vec: {'Truthfulness': (0.441025641025641, 0.06322475900481), 'Image Robustness': (0.358974358974359, 0.07548513560963974), 'Image Responsiveness': (0.7606837606837606, 0.03197997766473456), 'Stability': (0.5726495726495726, 0.052687299170675)}\n",
      "Computing Label\n",
      "Truthfulness: (0.5230769230769231, 0.0)\n",
      "Image Robustness: (0.07692307692307687, 0.0)\n",
      "Image Responsiveness: (0.794871794871795, 1.1102230246251565e-16)\n",
      "Stability: (0.0, 0.0)\n",
      "Method Label: {'Truthfulness': (0.5230769230769231, 0.0), 'Image Robustness': (0.07692307692307687, 0.0), 'Image Responsiveness': (0.794871794871795, 1.1102230246251565e-16), 'Stability': (0.0, 0.0)}\n",
      "Computing TCAV\n",
      "Truthfulness: (0.47179487179487173, 0.029009508971755773)\n",
      "Image Robustness: (0.7863247863247863, 0.05268729917067501)\n",
      "Image Responsiveness: (0.7606837606837606, 0.0846110678342877)\n",
      "Stability: (0.7435897435897436, 0.07252377242938955)\n",
      "Method TCAV: {'Truthfulness': (0.47179487179487173, 0.029009508971755773), 'Image Robustness': (0.7863247863247863, 0.05268729917067501), 'Image Responsiveness': (0.7606837606837606, 0.0846110678342877), 'Stability': (0.7435897435897436, 0.07252377242938955)}\n"
     ]
    }
   ],
   "source": [
    "for method,name in zip(vector_method,vector_names):\n",
    "    print(\"Computing {}\".format(name))\n",
    "    start = time.time()\n",
    "\n",
    "    results = compute_all_metrics(method,\n",
    "                                        dataset,\n",
    "                                        attributes,\n",
    "                                        seeds)\n",
    "    print(\"Method {}: {}\".format(name,results))\n",
    "    \n",
    "    name_lower = name.lower()\n",
    "    w = open(\"results/evaluation/{}_{}.txt\".format(dataset.experiment_name,name_lower),\"w\")\n",
    "    for key in results:\n",
    "        w.write(\"{}: {}\\n\".format(key,results[key]))\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005eade6",
   "metadata": {},
   "source": [
    "## Explain why CEM Vectors are Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecd8c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_method = {'cem': {}, \n",
    "'tcav': {}, \n",
    "'label': {}, \n",
    "'concept2vec': {}}\n",
    "\n",
    "for method,name in zip([load_cem_vectors_simple,load_tcav_vectors_simple,load_label_vectors_simple,load_concept2vec_vectors_simple],['cem','tcav','label','concept2vec']):\n",
    "    for dataset in [CUB_Dataset(),MNIST_Dataset(),Chexpert_Dataset(),DSprites_Dataset()]:\n",
    "        a = dataset.get_attributes() \n",
    "\n",
    "        similarities = []\n",
    "        avg_same_similarity = []\n",
    "        stds = []\n",
    "\n",
    "        for seed in [43,44,45]:\n",
    "            vectors = [np.mean(method(attribute,dataset,\"\",seed),axis=0) for attribute in a]\n",
    "            for i in vectors:\n",
    "                stds.append(np.std(i))\n",
    "            cosine_similarities_max = []\n",
    "            for i in range(len(vectors)):\n",
    "                cosine_similarities = max([1-cosine(vectors[i],vectors[j]) for j in range(len(vectors)) if i!=j])\n",
    "                cosine_similarities_max.append(cosine_similarities)\n",
    "            similarities.append(np.mean(cosine_similarities_max))\n",
    "\n",
    "        d = len(vectors[0])\n",
    "        std = np.mean(stds)\n",
    "        mean = np.mean(similarities)\n",
    "        z_score = (mean-0)/(d*std**4/(3**.5))\n",
    "        z_score *= len(attribute)**.5\n",
    "\n",
    "        results_by_method[name][dataset.experiment_name] = {\n",
    "            'dimension': d,\n",
    "            'std': float(std), \n",
    "            'mean_similarity': float(mean), \n",
    "            'std_similarity': float(np.std(similarities))\n",
    "        }\n",
    "json.dump(results_by_method,open('results/evaluation/ablation/randomness_cem_tcav.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06812c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 401408,\n",
       " 'std': 0.15072173073176476,\n",
       " 'mean_similarity': 0.6544520321994527,\n",
       " 'std_similarity': 0.010189191367382824}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_by_method['tcav']['cub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0bad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9443aa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['has_bill_shape::dagger',\n",
       " 'has_bill_shape::hooked_seabird',\n",
       " 'has_bill_shape::all-purpose',\n",
       " 'has_bill_shape::cone',\n",
       " 'has_wing_color::brown',\n",
       " 'has_wing_color::grey',\n",
       " 'has_wing_color::yellow',\n",
       " 'has_wing_color::black',\n",
       " 'has_wing_color::white',\n",
       " 'has_wing_color::buff',\n",
       " 'has_upperparts_color::brown',\n",
       " 'has_upperparts_color::grey',\n",
       " 'has_upperparts_color::yellow',\n",
       " 'has_upperparts_color::black',\n",
       " 'has_upperparts_color::white',\n",
       " 'has_upperparts_color::buff',\n",
       " 'has_underparts_color::brown',\n",
       " 'has_underparts_color::grey',\n",
       " 'has_underparts_color::yellow',\n",
       " 'has_underparts_color::black',\n",
       " 'has_underparts_color::white',\n",
       " 'has_underparts_color::buff',\n",
       " 'has_breast_pattern::solid',\n",
       " 'has_breast_pattern::striped',\n",
       " 'has_breast_pattern::multi-colored',\n",
       " 'has_back_color::brown',\n",
       " 'has_back_color::grey',\n",
       " 'has_back_color::yellow',\n",
       " 'has_back_color::black',\n",
       " 'has_back_color::white',\n",
       " 'has_back_color::buff',\n",
       " 'has_tail_shape::notched_tail',\n",
       " 'has_upper_tail_color::brown',\n",
       " 'has_upper_tail_color::grey',\n",
       " 'has_upper_tail_color::black',\n",
       " 'has_upper_tail_color::white',\n",
       " 'has_upper_tail_color::buff',\n",
       " 'has_head_pattern::eyebrow',\n",
       " 'has_head_pattern::plain',\n",
       " 'has_breast_color::brown',\n",
       " 'has_breast_color::grey',\n",
       " 'has_breast_color::yellow',\n",
       " 'has_breast_color::black',\n",
       " 'has_breast_color::white',\n",
       " 'has_breast_color::buff',\n",
       " 'has_throat_color::grey',\n",
       " 'has_throat_color::yellow',\n",
       " 'has_throat_color::black',\n",
       " 'has_throat_color::white',\n",
       " 'has_throat_color::buff',\n",
       " 'has_eye_color::black',\n",
       " 'has_bill_length::about_the_same_as_head',\n",
       " 'has_bill_length::shorter_than_head',\n",
       " 'has_forehead_color::blue',\n",
       " 'has_forehead_color::brown',\n",
       " 'has_forehead_color::grey',\n",
       " 'has_forehead_color::yellow',\n",
       " 'has_forehead_color::black',\n",
       " 'has_forehead_color::white',\n",
       " 'has_under_tail_color::brown',\n",
       " 'has_under_tail_color::grey',\n",
       " 'has_under_tail_color::black',\n",
       " 'has_under_tail_color::white',\n",
       " 'has_under_tail_color::buff',\n",
       " 'has_nape_color::brown',\n",
       " 'has_nape_color::grey',\n",
       " 'has_nape_color::yellow',\n",
       " 'has_nape_color::black',\n",
       " 'has_nape_color::white',\n",
       " 'has_nape_color::buff',\n",
       " 'has_belly_color::brown',\n",
       " 'has_belly_color::grey',\n",
       " 'has_belly_color::yellow',\n",
       " 'has_belly_color::black',\n",
       " 'has_belly_color::white',\n",
       " 'has_belly_color::buff',\n",
       " 'has_wing_shape::rounded-wings',\n",
       " 'has_wing_shape::pointed-wings',\n",
       " 'has_size::small_(5_-_9_in)',\n",
       " 'has_size::medium_(9_-_16_in)',\n",
       " 'has_size::very_small_(3_-_5_in)',\n",
       " 'has_shape::duck-like',\n",
       " 'has_shape::perching-like',\n",
       " 'has_back_pattern::solid',\n",
       " 'has_back_pattern::striped',\n",
       " 'has_back_pattern::multi-colored',\n",
       " 'has_tail_pattern::solid',\n",
       " 'has_tail_pattern::striped',\n",
       " 'has_tail_pattern::multi-colored',\n",
       " 'has_belly_pattern::solid',\n",
       " 'has_primary_color::brown',\n",
       " 'has_primary_color::grey',\n",
       " 'has_primary_color::yellow',\n",
       " 'has_primary_color::black',\n",
       " 'has_primary_color::white',\n",
       " 'has_primary_color::buff',\n",
       " 'has_leg_color::grey',\n",
       " 'has_leg_color::black',\n",
       " 'has_leg_color::buff',\n",
       " 'has_bill_color::grey',\n",
       " 'has_bill_color::black',\n",
       " 'has_bill_color::buff',\n",
       " 'has_crown_color::blue',\n",
       " 'has_crown_color::brown',\n",
       " 'has_crown_color::grey',\n",
       " 'has_crown_color::yellow',\n",
       " 'has_crown_color::black',\n",
       " 'has_crown_color::white',\n",
       " 'has_wing_pattern::solid',\n",
       " 'has_wing_pattern::spotted',\n",
       " 'has_wing_pattern::striped',\n",
       " 'has_wing_pattern::multi-colored']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUB_Dataset().get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "590e5dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_concept2vec_vectors_simple(\"5_color\",MNIST_Dataset(),\"\",43).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e954226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 676us/step - loss: 0.5155\n",
      "500/500 [==============================] - 0s 655us/step - loss: 0.3021\n",
      "500/500 [==============================] - 0s 672us/step - loss: 0.1763\n",
      "500/500 [==============================] - 0s 673us/step - loss: 0.0725\n",
      "500/500 [==============================] - 0s 665us/step - loss: 0.0316\n"
     ]
    }
   ],
   "source": [
    "create_concept2vec(MNIST_Dataset(),\"\",43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f723805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_color',\n",
       " '0_number',\n",
       " '1_color',\n",
       " '1_number',\n",
       " '2_color',\n",
       " '2_number',\n",
       " '3_color',\n",
       " '3_number',\n",
       " '4_color',\n",
       " '4_number',\n",
       " '5_color',\n",
       " '5_number',\n",
       " '6_color',\n",
       " '6_number',\n",
       " '7_color',\n",
       " '7_number',\n",
       " '8_color',\n",
       " '8_number',\n",
       " '9_color',\n",
       " '9_number']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd22e64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function src.concept_vectors.load_concept2vec_vectors_simple(attribute, dataset, suffix, seed=-1)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_concept2vec_vectors_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b6544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cem': {'cub': {'dimension': 16,\n",
       "   'std': 1.0710860318615494,\n",
       "   'mean_similarity': 0.04315607335729071,\n",
       "   'z_score': 0.019763597090416498},\n",
       "  'mnist': {'dimension': 16,\n",
       "   'std': 0.3603748546133479,\n",
       "   'mean_similarity': -0.23096284300518896,\n",
       "   'z_score': -4.192854909517109},\n",
       "  'chexpert': {'dimension': 32,\n",
       "   'std': 0.7383034818894332,\n",
       "   'mean_similarity': 0.2269337003345913,\n",
       "   'z_score': 0.1601089490787698},\n",
       "  'dsprites': {'dimension': 32,\n",
       "   'std': 0.8814139286781008,\n",
       "   'mean_similarity': 0.2441086504661453,\n",
       "   'z_score': 0.0579192863227851}},\n",
       " 'tcav': {'cub': {'dimension': 401408,\n",
       "   'std': 0.15072173073176479,\n",
       "   'mean_similarity': 0.5211380636473188,\n",
       "   'z_score': 0.024260779783046957},\n",
       "  'mnist': {'dimension': 401408,\n",
       "   'std': 0.2327976155578189,\n",
       "   'mean_similarity': 0.6249369905391176,\n",
       "   'z_score': 0.0025968192268532434},\n",
       "  'chexpert': {'dimension': 401408,\n",
       "   'std': 0.08216722796770931,\n",
       "   'mean_similarity': 0.6034696662843769,\n",
       "   'z_score': 0.22124890783590814},\n",
       "  'dsprites': {'dimension': 401408,\n",
       "   'std': 0.18750643071030956,\n",
       "   'mean_similarity': 0.7683219493178904,\n",
       "   'z_score': 0.007095813567566484}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_by_method['label']['mnist']['z_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcc8f2",
   "metadata": {},
   "source": [
    "## Analyze impact of vector metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_by_metric = {}\n",
    "dataset = CUB_Dataset()\n",
    "attributes = dataset.get_attributes()\n",
    "for metric in ['euclidean','cosine','manhattan']:\n",
    "    hierarchy_by_metric[metric] = {}\n",
    "\n",
    "    for function,name in zip([load_label_vectors_simple,\n",
    "    load_shapley_vectors_simple, \n",
    "    load_cem_vectors_simple,\n",
    "    load_concept2vec_vectors_simple\n",
    "    ],['label','shapley','cem','concept2vec']):\n",
    "        hierarchy_by_metric[metric][name] = {}\n",
    "        for seed in [43,44,45]:\n",
    "            hierarchy_by_metric[metric][name][seed] = flat_distance_to_square(get_concept_distances(function,dataset,'',attributes,seed,metric=metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85df602",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pairwise_distance = {}\n",
    "for name in ['label','shapley','cem','concept2vec']:\n",
    "    avg_pairwise_distance[name] = {}\n",
    "    for metric_1 in ['euclidean','cosine','manhattan']:\n",
    "        avg_pairwise_distance[name][metric_1] = {}\n",
    "        for metric_2 in ['euclidean','cosine','manhattan']:\n",
    "            h1 = hierarchy_by_metric[metric_1][name]\n",
    "            h2 = hierarchy_by_metric[metric_2][name]\n",
    "            results = [embedding_distance(h1[seed],h2[seed],k=3) for seed in [43,44,45]]\n",
    "            avg_pairwise_distance[name][metric_1][metric_2] = (np.mean(results),np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94232646",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(avg_pairwise_distance,open('results/evaluation/ablation/metric_distances.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ba6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_object_by_metric = {}\n",
    "dataset = CUB_Dataset()\n",
    "attributes = dataset.get_attributes()\n",
    "for metric in ['euclidean','cosine','manhattan']:\n",
    "    hierarchy_object_by_metric[metric] = {}\n",
    "\n",
    "    for function,name in zip([load_label_vectors_simple,\n",
    "    load_shapley_vectors_simple, \n",
    "    load_cem_vectors_simple,\n",
    "    load_concept2vec_vectors_simple\n",
    "    ],['label','shapley','cem','concept2vec']):\n",
    "        hierarchy_object_by_metric[metric][name] = {}\n",
    "        for seed in [43,44,45]:\n",
    "            hierarchy_object_by_metric[metric][name][seed] = create_hierarchy(create_ward_hierarchy,function,dataset,'',attributes,seed,metric=metric) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac42b2",
   "metadata": {},
   "source": [
    "### Investigate why this occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_hierarchy = hierarchy_object_by_metric['cosine']['label'][43]\n",
    "euclidean_hierarchy = hierarchy_object_by_metric['euclidean']['label'][43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_euclidean = get_top_k_pairs(hierarchy_by_metric['euclidean']['label'][43],k=3)\n",
    "top_k_cosine = get_top_k_pairs(hierarchy_by_metric['cosine']['label'][43],k=3)\n",
    "\n",
    "top_k_euclidean = [(attributes[i[0]],attributes[i[1]]) for i in top_k_euclidean]\n",
    "top_k_cosine = [(attributes[i[0]],attributes[i[1]]) for i in top_k_cosine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = [np.mean([embedding_distance(hierarchy_by_metric['cosine']['label'][seed],hierarchy_by_metric['euclidean']['label'][seed],k=k) for seed in [43,44,45]]) for k in range(1,110)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc784de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7053571428571429, 0.7291666666666666)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent_euclidean_agree = len([i for i in top_k_euclidean if i[0].split(\"::\")[1] == i[1].split(\"::\")[1]])/len(top_k_euclidean)\n",
    "percent_cosine_agree = len([i for i in top_k_cosine if i[0].split(\"::\")[1] == i[1].split(\"::\")[1]])/len(top_k_euclidean)\n",
    "percent_euclidean_agree,percent_cosine_agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebda76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7053571428571428, 0.7291666666666666)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_top_k_euclidean = []\n",
    "all_top_k_cosine = []\n",
    "\n",
    "for seed in [43,44,45]:\n",
    "    top_k_euclidean = get_top_k_pairs(hierarchy_by_metric['euclidean']['label'][seed],k=3)\n",
    "    top_k_cosine = get_top_k_pairs(hierarchy_by_metric['cosine']['label'][seed],k=3)\n",
    "\n",
    "    top_k_euclidean = [(attributes[i[0]],attributes[i[1]]) for i in top_k_euclidean]\n",
    "    top_k_cosine = [(attributes[i[0]],attributes[i[1]]) for i in top_k_cosine]\n",
    "\n",
    "    all_top_k_euclidean += top_k_euclidean\n",
    "    all_top_k_cosine += top_k_cosine\n",
    "\n",
    "\n",
    "percent_euclidean_agree = len([i for i in all_top_k_euclidean if i[0].split(\"::\")[1] == i[1].split(\"::\")[1]])/len(top_k_euclidean)\n",
    "percent_cosine_agree = len([i for i in all_top_k_cosine if i[0].split(\"::\")[1] == i[1].split(\"::\")[1]])/len(top_k_euclidean)\n",
    "percent_euclidean_agree/3, percent_cosine_agree/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump({\n",
    "    'all_distances': all_distances, \n",
    "    'top_k_euclidean': top_k_euclidean, \n",
    "    'top_k_cosine': top_k_cosine, \n",
    "    'percent_euclidean_agree': percent_euclidean_agree/3, \n",
    "    'percent_cosine_agree': percent_cosine_agree/3, \n",
    "},open('results/evaluation/ablation/distance_cosine_euclidean_top_k.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddfd66",
   "metadata": {},
   "source": [
    "## Analyze Hierarchy Similairty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c00faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_by_dataset = defaultdict(lambda: defaultdict(dict))\n",
    "for dataset_function,dataset_name in zip([CUB_Dataset, MNIST_Dataset, DSprites_Dataset, Chexpert_Dataset],['cub','mnist','dsprites','chexpert']):\n",
    "    dataset = dataset_function()\n",
    "    attributes = dataset.get_attributes()\n",
    "\n",
    "    for function,name in zip([load_label_vectors_simple,\n",
    "    load_shapley_vectors_simple, \n",
    "    load_cem_vectors_simple,\n",
    "    load_concept2vec_vectors_simple\n",
    "    ],['label','shapley','cem','concept2vec']):\n",
    "        hierarchy_by_metric[metric][name] = {}\n",
    "        for seed in [43,44,45]:\n",
    "            hierarchy_by_dataset[dataset_name][name][seed] = flat_distance_to_square(get_concept_distances(function,dataset,'',attributes,seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_by_dataset = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for dataset in ['cub','mnist','dsprites','chexpert']:\n",
    "    for name in ['cem','shapley','label','concept2vec']:\n",
    "        for name_2 in ['cem','shapley','label','concept2vec']:\n",
    "            h1 = hierarchy_by_dataset[dataset][name]\n",
    "            h2 = hierarchy_by_dataset[dataset][name_2]\n",
    "            distance_by_dataset[dataset][name][name_2] = [embedding_distance(h1[seed],h2[seed],k=3) for seed in [43,44,45]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e83a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_cub = np.array([[distance_by_dataset['cub'][i][j] for j in distance_by_dataset['cub'][i]] for i in distance_by_dataset['cub']])\n",
    "distances_cub = np.mean(distances_cub,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['cem','shapley','label','concept2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(distances_cub.tolist(), open('results/evaluation/ablation/distance_between_hierarchies.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb37286",
   "metadata": {},
   "source": [
    "## CUB Ablation Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c690e1f",
   "metadata": {},
   "source": [
    "### Evaluation at different noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7e6af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CUB_Dataset()\n",
    "attributes = dataset.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd48ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_method = load_shapley_vectors_simple\n",
    "name = \"Shapley\"\n",
    "random_seeds = [43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72ba733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for flip_prob in ['0.01','0.05','0.1']:\n",
    "    results['flip_prob_{}'.format(flip_prob)] = compare_same_images_by_suffix(embedding_method,\n",
    "                                         dataset,attributes,random_seeds,\"_flip_{}\".format(flip_prob),\n",
    "                                        baseline_hierarchies=None)\n",
    "\n",
    "for noise in [25,50,100]:\n",
    "    results['noise_{}'.format(flip_prob)] = compare_same_images_by_suffix(embedding_method,\n",
    "                                         dataset,attributes,random_seeds,\"_noise_{}\".format(noise),\n",
    "                                        baseline_hierarchies=None)\n",
    "\n",
    "w = open(\"results/evaluation/cub_noise_ablation.txt\",\"w\")\n",
    "for key in results:\n",
    "    w.write(\"{}: {}\\n\".format(key,results[key]))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328a2b4",
   "metadata": {},
   "source": [
    "### See how truthfulness hyperparameters impact things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dfd1588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1198 validated image filenames belonging to 200 classes.\n",
      "38/38 [==============================] - 199s 5s/step\n",
      "Found 1198 validated image filenames belonging to 200 classes.\n",
      "38/38 [==============================] - 199s 5s/step\n",
      "Found 1198 validated image filenames belonging to 200 classes.\n",
      "38/38 [==============================] - 200s 5s/step\n",
      "Found 1198 validated image filenames belonging to 200 classes.\n",
      "38/38 [==============================] - 200s 5s/step\n"
     ]
    }
   ],
   "source": [
    "dataset = CUB_Dataset()\n",
    "attributes = dataset.get_attributes()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for compare_concept in [1,3,5,7]:\n",
    "    results[compare_concept] = truthfulness_metric_shapley(load_shapley_vectors_simple,dataset,attributes,\n",
    "                                                           [43,44,45],model_name=\"VGG16\",compare_concepts=compare_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92353971",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = open(\"results/evaluation/cub_truthfulness_ablation.txt\",\"w\")\n",
    "for key in results:\n",
    "    w.write(\"{}: {}\\n\".format(key,results[key]))\n",
    "w.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
