{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86d7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87aeb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8d1267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 18:10:43.397719: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 18:10:51.593707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ../../anaconda3/lib\n",
      "2023-04-22 18:10:51.598270: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ../../anaconda3/lib\n",
      "2023-04-22 18:10:51.598288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from experiments import intervention_utils\n",
    "import os\n",
    "from cem.data.CUB200.cub_loader import load_data, find_class_imbalance\n",
    "from torchvision.models import resnet50, resnet34\n",
    "from cem.models.cem import ConceptEmbeddingModel\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import cem.train.training as cem_train\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from cem.models.vae_model import *\n",
    "from cem.metrics.homogeneity import embedding_homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d41cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.tab10.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6654c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUB_DIR = 'CUB/'\n",
    "BASE_DIR = os.path.join(CUB_DIR, 'images/CUB_200_2011/images')\n",
    "num_workers=8\n",
    "n_tasks = 200\n",
    "n_concepts = 112\n",
    "gpu = 0\n",
    "sample_train = 0.1\n",
    "concept_group_map = intervention_utils.CUB_CONCEPT_GROUP_MAP\n",
    "num_epochs = 100\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9c4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments.extract_cem_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f28e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = experiments.extract_cem_concepts.generate_data_loaders_dsprites(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37934e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = pickle.load(open(\"dsprites/preprocessed/test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aa75f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 715240,\n",
       " 'img_path': 'dsprites/images/715240.png',\n",
       " 'class_label': 147786,\n",
       " 'attribute_label': [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fffba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]]],\n",
       " \n",
       " \n",
       "         [[[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500]]],\n",
       " \n",
       " \n",
       "         [[[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]]],\n",
       " \n",
       " \n",
       "         [[[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [-0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [-0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [-0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]]],\n",
       " \n",
       " \n",
       "         [[[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [-0.2500, -0.2500, -0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           ...,\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.2500,  0.2500,  0.2500,  ..., -0.2500, -0.2500, -0.2500]]]]),\n",
       " tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
       "         53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
       "         53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
       "         53, 53, 53, 53, 53, 53, 53, 53, 53, 53]),\n",
       " tensor([[1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf4197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(CUB_DIR, 'preprocessed/train.pkl')\n",
    "val_data_path = train_data_path.replace('train.pkl', 'val.pkl')\n",
    "test_data_path = train_data_path.replace('train.pkl', 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d876af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = joblib.load(\"results/ConceptEmbeddingModelNew_resnet34_fold_1_experiment_config.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746a3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['weight_loss']:\n",
    "    imbalance = find_class_imbalance(train_data_path, True)\n",
    "else:\n",
    "    imbalance = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f88025e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_concepts = np.arange(n_concepts)\n",
    "def subsample_transform(sample):\n",
    "    if isinstance(sample, list):\n",
    "        sample = np.array(sample)\n",
    "    return sample[selected_concepts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe087714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = load_data(\n",
    "    pkl_paths=[train_data_path],\n",
    "    use_attr=True,\n",
    "    no_img=False,\n",
    "    batch_size=config['batch_size'],\n",
    "    uncertain_label=False,\n",
    "    n_class_attr=2,\n",
    "    image_dir='images',\n",
    "    resampling=False,\n",
    "    root_dir='.',\n",
    "    num_workers=config['num_workers'],\n",
    "    concept_transform=subsample_transform,\n",
    "    path_transform=lambda path: path.replace(\"CUB//\",\"\"),\n",
    ")\n",
    "val_dl = load_data(\n",
    "    pkl_paths=[val_data_path],\n",
    "    use_attr=True,\n",
    "    no_img=False,\n",
    "    batch_size=config['batch_size'],\n",
    "    uncertain_label=False,\n",
    "    n_class_attr=2,\n",
    "    image_dir='images',\n",
    "    resampling=False,\n",
    "    root_dir='.',\n",
    "    num_workers=config['num_workers'],\n",
    "    concept_transform=subsample_transform,\n",
    "    path_transform=lambda path: path.replace(\"CUB//\",\"\"))\n",
    "test_dl = load_data(\n",
    "    pkl_paths=[test_data_path],\n",
    "    use_attr=True,\n",
    "    no_img=False,\n",
    "    batch_size=config['batch_size'],\n",
    "    uncertain_label=False,\n",
    "    n_class_attr=2,\n",
    "    image_dir='images',\n",
    "    resampling=False,\n",
    "    root_dir='.',\n",
    "    num_workers=config['num_workers'],\n",
    "    concept_transform=subsample_transform,\n",
    "    path_transform=lambda path: path.replace(\"CUB//\",\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a3b9450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/user/njr61/hpc-work/anaconda3/envs/cem/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/rds/user/njr61/hpc-work/anaconda3/envs/cem/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = intervention_utils.load_trained_model(\n",
    "        config=config,\n",
    "        n_tasks=n_tasks,\n",
    "        n_concepts=n_concepts,\n",
    "        result_dir=\"results/\",\n",
    "        split=0,\n",
    "        imbalance=imbalance,\n",
    "        intervention_idxs=[],\n",
    "        train_dl=train_dl,\n",
    "        sequential=False,\n",
    "        independent=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa455759",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "y_all = []\n",
    "c_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbc72597",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_dl:\n",
    "    x, y, c = batch\n",
    "    x_all.append(x)\n",
    "    y_all.append(y)\n",
    "    c_all.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6da2d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = torch.cat(x_all, dim=0)\n",
    "y_all = torch.cat(y_all, dim=0)\n",
    "c_all = torch.cat(c_all, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ff88bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78ba8515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1198, 112]),\n",
       " torch.Size([1198, 224]),\n",
       " torch.Size([1198, 200]),\n",
       " torch.Size([112, 1198, 4])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[results[i].shape for i in range(len(results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86694430",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred, c_emb, y_pred, _ = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0406574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred = c_pred.detach()\n",
    "c_emb = c_emb.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cb4456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18452380952381, 0.018697539184584857)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b376012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.concept_folder_location = \"cem_concepts/cub/42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fec85588",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.experiment_name = \"cub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85744494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "            gpus=gpu,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38fa0a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41da5a0e01664a6684e7a54bb2b745aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_c_accuracy': 0.95804762840271,\n",
       "  'test_c_auc': 0.9330776333808899,\n",
       "  'test_c_f1': 0.9353863000869751,\n",
       "  'test_y_accuracy': 0.7562604546546936,\n",
       "  'test_y_auc': 0.0,\n",
       "  'test_y_f1': 0.6388682126998901,\n",
       "  'test_concept_loss': 0.5386481881141663,\n",
       "  'test_task_loss': 1.2954771518707275,\n",
       "  'test_loss': 3.988718271255493,\n",
       "  'test_avg_c_y_acc': 0.8571540713310242}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, val_dl, verbose=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f521573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write_concepts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa941955",
   "metadata": {},
   "source": [
    "## Create test npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd97785",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file_loc = \"../../spurious-concepts/ConceptBottleneck/valid_c.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfab9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_c_predicted = np.load(open(val_file_loc,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73cecca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "valid_pkl = pickle.load(open(\"CUB/preprocessed/val.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7857abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_c = np.stack([i['attribute_label'] for i in valid_pkl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "716b6b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015027710813242504"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((valid_c_predicted-valid_c)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6423173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_loc = \"../../spurious-concepts/ConceptBottleneck/test_c.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b136c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_c_predicted = np.load(open(test_file_loc,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4337075",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pkl = pickle.load(open(\"CUB/preprocessed/test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75e256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_c = np.stack([i['attribute_label'] for i in test_pkl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af749b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034268729168837234"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((test_c_predicted-test_c)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "238da1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_loc = \"../../spurious-concepts/ConceptBottleneck/train_c.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2700a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c_predicted = np.load(open(train_file_loc,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c514235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl = pickle.load(open(\"CUB/preprocessed/train.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a306a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c = np.stack([i['attribute_label'] for i in train_pkl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2a74966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014827635405120727"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((train_c_predicted-train_c)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba46c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c57221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({21: 23,\n",
       "         51: 23,\n",
       "         62: 27,\n",
       "         168: 22,\n",
       "         0: 26,\n",
       "         70: 22,\n",
       "         24: 27,\n",
       "         100: 22,\n",
       "         96: 28,\n",
       "         126: 26,\n",
       "         186: 27,\n",
       "         188: 20,\n",
       "         34: 21,\n",
       "         160: 22,\n",
       "         148: 25,\n",
       "         48: 22,\n",
       "         53: 23,\n",
       "         122: 24,\n",
       "         174: 22,\n",
       "         31: 19,\n",
       "         32: 28,\n",
       "         132: 24,\n",
       "         153: 26,\n",
       "         12: 27,\n",
       "         68: 22,\n",
       "         15: 24,\n",
       "         102: 26,\n",
       "         144: 23,\n",
       "         80: 26,\n",
       "         30: 22,\n",
       "         115: 26,\n",
       "         123: 25,\n",
       "         177: 26,\n",
       "         134: 26,\n",
       "         166: 24,\n",
       "         103: 24,\n",
       "         184: 25,\n",
       "         193: 23,\n",
       "         147: 21,\n",
       "         1: 22,\n",
       "         187: 23,\n",
       "         79: 28,\n",
       "         107: 26,\n",
       "         178: 25,\n",
       "         47: 22,\n",
       "         55: 27,\n",
       "         141: 20,\n",
       "         119: 25,\n",
       "         142: 25,\n",
       "         39: 24,\n",
       "         88: 23,\n",
       "         196: 24,\n",
       "         151: 24,\n",
       "         63: 26,\n",
       "         170: 27,\n",
       "         179: 29,\n",
       "         57: 23,\n",
       "         181: 26,\n",
       "         114: 25,\n",
       "         81: 27,\n",
       "         54: 28,\n",
       "         20: 27,\n",
       "         149: 25,\n",
       "         137: 25,\n",
       "         101: 24,\n",
       "         191: 26,\n",
       "         61: 20,\n",
       "         146: 24,\n",
       "         44: 25,\n",
       "         95: 25,\n",
       "         135: 28,\n",
       "         56: 20,\n",
       "         42: 27,\n",
       "         165: 26,\n",
       "         83: 24,\n",
       "         161: 25,\n",
       "         78: 19,\n",
       "         110: 23,\n",
       "         140: 23,\n",
       "         65: 21,\n",
       "         82: 19,\n",
       "         13: 23,\n",
       "         163: 21,\n",
       "         18: 22,\n",
       "         108: 22,\n",
       "         5: 27,\n",
       "         29: 23,\n",
       "         58: 23,\n",
       "         66: 21,\n",
       "         17: 25,\n",
       "         87: 24,\n",
       "         99: 25,\n",
       "         138: 24,\n",
       "         69: 24,\n",
       "         120: 25,\n",
       "         74: 25,\n",
       "         98: 26,\n",
       "         133: 23,\n",
       "         19: 28,\n",
       "         91: 23,\n",
       "         197: 24,\n",
       "         127: 22,\n",
       "         60: 26,\n",
       "         97: 23,\n",
       "         36: 24,\n",
       "         23: 22,\n",
       "         105: 27,\n",
       "         195: 25,\n",
       "         164: 25,\n",
       "         159: 23,\n",
       "         129: 21,\n",
       "         118: 27,\n",
       "         7: 24,\n",
       "         157: 20,\n",
       "         67: 23,\n",
       "         180: 25,\n",
       "         92: 25,\n",
       "         28: 23,\n",
       "         150: 24,\n",
       "         117: 25,\n",
       "         40: 22,\n",
       "         182: 22,\n",
       "         2: 23,\n",
       "         85: 27,\n",
       "         94: 26,\n",
       "         199: 26,\n",
       "         128: 20,\n",
       "         35: 22,\n",
       "         131: 24,\n",
       "         113: 24,\n",
       "         45: 22,\n",
       "         198: 26,\n",
       "         77: 23,\n",
       "         121: 19,\n",
       "         10: 25,\n",
       "         155: 21,\n",
       "         71: 24,\n",
       "         176: 24,\n",
       "         169: 26,\n",
       "         89: 22,\n",
       "         162: 23,\n",
       "         185: 24,\n",
       "         86: 27,\n",
       "         158: 28,\n",
       "         14: 22,\n",
       "         190: 25,\n",
       "         90: 26,\n",
       "         11: 26,\n",
       "         16: 24,\n",
       "         189: 25,\n",
       "         26: 22,\n",
       "         173: 21,\n",
       "         175: 26,\n",
       "         75: 26,\n",
       "         154: 24,\n",
       "         49: 26,\n",
       "         130: 21,\n",
       "         116: 26,\n",
       "         27: 23,\n",
       "         145: 26,\n",
       "         104: 26,\n",
       "         72: 26,\n",
       "         4: 23,\n",
       "         37: 25,\n",
       "         22: 27,\n",
       "         167: 27,\n",
       "         33: 20,\n",
       "         124: 22,\n",
       "         125: 20,\n",
       "         93: 22,\n",
       "         38: 23,\n",
       "         25: 24,\n",
       "         156: 20,\n",
       "         3: 24,\n",
       "         84: 27,\n",
       "         41: 16,\n",
       "         183: 24,\n",
       "         59: 26,\n",
       "         76: 24,\n",
       "         143: 22,\n",
       "         136: 22,\n",
       "         6: 28,\n",
       "         43: 23,\n",
       "         73: 27,\n",
       "         192: 20,\n",
       "         52: 27,\n",
       "         46: 23,\n",
       "         111: 23,\n",
       "         152: 21,\n",
       "         9: 22,\n",
       "         64: 25,\n",
       "         171: 25,\n",
       "         139: 26,\n",
       "         50: 22,\n",
       "         112: 21,\n",
       "         194: 24,\n",
       "         172: 25,\n",
       "         109: 23,\n",
       "         106: 25,\n",
       "         8: 21})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([i['class_label'] for i in train_pkl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6351f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 30,\n",
       "         1: 30,\n",
       "         2: 28,\n",
       "         3: 30,\n",
       "         4: 14,\n",
       "         5: 11,\n",
       "         6: 23,\n",
       "         7: 18,\n",
       "         8: 29,\n",
       "         9: 30,\n",
       "         10: 30,\n",
       "         11: 26,\n",
       "         12: 30,\n",
       "         13: 30,\n",
       "         14: 28,\n",
       "         15: 28,\n",
       "         16: 27,\n",
       "         17: 15,\n",
       "         18: 29,\n",
       "         19: 29,\n",
       "         20: 30,\n",
       "         21: 26,\n",
       "         22: 29,\n",
       "         23: 22,\n",
       "         24: 30,\n",
       "         25: 30,\n",
       "         26: 30,\n",
       "         27: 29,\n",
       "         28: 30,\n",
       "         29: 30,\n",
       "         30: 30,\n",
       "         31: 23,\n",
       "         32: 29,\n",
       "         33: 29,\n",
       "         34: 30,\n",
       "         35: 30,\n",
       "         36: 29,\n",
       "         37: 30,\n",
       "         38: 29,\n",
       "         39: 30,\n",
       "         40: 30,\n",
       "         41: 30,\n",
       "         42: 29,\n",
       "         43: 30,\n",
       "         44: 30,\n",
       "         45: 30,\n",
       "         46: 30,\n",
       "         47: 30,\n",
       "         48: 30,\n",
       "         49: 30,\n",
       "         50: 30,\n",
       "         51: 30,\n",
       "         52: 30,\n",
       "         53: 30,\n",
       "         54: 30,\n",
       "         55: 30,\n",
       "         56: 30,\n",
       "         57: 28,\n",
       "         58: 30,\n",
       "         59: 29,\n",
       "         60: 30,\n",
       "         61: 30,\n",
       "         62: 30,\n",
       "         63: 30,\n",
       "         64: 20,\n",
       "         65: 30,\n",
       "         66: 30,\n",
       "         67: 30,\n",
       "         68: 30,\n",
       "         69: 30,\n",
       "         70: 30,\n",
       "         71: 30,\n",
       "         72: 30,\n",
       "         73: 30,\n",
       "         74: 27,\n",
       "         75: 30,\n",
       "         76: 30,\n",
       "         77: 29,\n",
       "         78: 30,\n",
       "         79: 30,\n",
       "         80: 30,\n",
       "         81: 30,\n",
       "         82: 30,\n",
       "         83: 23,\n",
       "         84: 30,\n",
       "         85: 30,\n",
       "         86: 30,\n",
       "         87: 30,\n",
       "         88: 30,\n",
       "         89: 30,\n",
       "         90: 30,\n",
       "         91: 30,\n",
       "         92: 30,\n",
       "         93: 30,\n",
       "         94: 30,\n",
       "         95: 30,\n",
       "         96: 29,\n",
       "         97: 30,\n",
       "         98: 30,\n",
       "         99: 30,\n",
       "         100: 20,\n",
       "         101: 30,\n",
       "         102: 30,\n",
       "         103: 30,\n",
       "         104: 19,\n",
       "         105: 30,\n",
       "         106: 30,\n",
       "         107: 30,\n",
       "         108: 30,\n",
       "         109: 30,\n",
       "         110: 30,\n",
       "         111: 30,\n",
       "         112: 20,\n",
       "         113: 30,\n",
       "         114: 29,\n",
       "         115: 30,\n",
       "         116: 29,\n",
       "         117: 30,\n",
       "         118: 29,\n",
       "         119: 30,\n",
       "         120: 30,\n",
       "         121: 30,\n",
       "         122: 30,\n",
       "         123: 29,\n",
       "         124: 29,\n",
       "         125: 30,\n",
       "         126: 30,\n",
       "         127: 30,\n",
       "         128: 30,\n",
       "         129: 30,\n",
       "         130: 30,\n",
       "         131: 30,\n",
       "         132: 30,\n",
       "         133: 30,\n",
       "         134: 30,\n",
       "         135: 30,\n",
       "         136: 30,\n",
       "         137: 30,\n",
       "         138: 30,\n",
       "         139: 30,\n",
       "         140: 29,\n",
       "         141: 30,\n",
       "         142: 30,\n",
       "         143: 30,\n",
       "         144: 30,\n",
       "         145: 30,\n",
       "         146: 30,\n",
       "         147: 30,\n",
       "         148: 29,\n",
       "         149: 30,\n",
       "         150: 21,\n",
       "         151: 30,\n",
       "         152: 29,\n",
       "         153: 30,\n",
       "         154: 30,\n",
       "         155: 30,\n",
       "         156: 29,\n",
       "         157: 30,\n",
       "         158: 30,\n",
       "         159: 29,\n",
       "         160: 30,\n",
       "         161: 30,\n",
       "         162: 30,\n",
       "         163: 30,\n",
       "         164: 30,\n",
       "         165: 29,\n",
       "         166: 30,\n",
       "         167: 29,\n",
       "         168: 29,\n",
       "         169: 30,\n",
       "         170: 30,\n",
       "         171: 30,\n",
       "         172: 30,\n",
       "         173: 30,\n",
       "         174: 30,\n",
       "         175: 30,\n",
       "         176: 30,\n",
       "         177: 26,\n",
       "         178: 29,\n",
       "         179: 30,\n",
       "         180: 29,\n",
       "         181: 30,\n",
       "         182: 30,\n",
       "         183: 30,\n",
       "         184: 30,\n",
       "         185: 30,\n",
       "         186: 20,\n",
       "         187: 30,\n",
       "         188: 30,\n",
       "         189: 29,\n",
       "         190: 30,\n",
       "         191: 30,\n",
       "         192: 30,\n",
       "         193: 30,\n",
       "         194: 30,\n",
       "         195: 30,\n",
       "         196: 30,\n",
       "         197: 30,\n",
       "         198: 30,\n",
       "         199: 30})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([i['class_label'] for i in test_pkl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3ea58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
